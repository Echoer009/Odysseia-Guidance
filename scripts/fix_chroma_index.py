#!/usr/bin/env python
# -*- coding: utf-8 -*-

import chromadb
import sys
import time

# === é…ç½®åŒº ===
# è¯·ç¡®ä¿æ­¤è·¯å¾„ç›¸å¯¹äºæ‚¨è¿è¡Œè„šæœ¬çš„æ ¹ç›®å½•æ˜¯æ­£ç¡®çš„
PERSIST_DIRECTORY = "data/forum_chroma_db"
# è¿™æ˜¯æ‚¨åœ¨æ—¥å¿—ä¸­å´©æºƒæ—¶æ“ä½œçš„é›†åˆåç§°
COLLECTION_NAME = "forum_threads"
# ============


def fix_index():
    """
    é€šè¿‡å°†æ•°æ®è¯»å‡ºã€åˆ é™¤æ—§é›†åˆã€é‡å»ºæ–°é›†åˆå¹¶å†™å›æ•°æ®çš„æ–¹å¼ï¼Œå¼ºåˆ¶é‡å»º ChromaDB é›†åˆçš„ç´¢å¼•ã€‚
    """
    print(f"ğŸ”§ æ­£åœ¨è¿æ¥ ChromaDBï¼Œæ•°æ®ç›®å½•: {PERSIST_DIRECTORY} ...")
    try:
        client = chromadb.PersistentClient(path=PERSIST_DIRECTORY)
        # å°è¯•è·å–é›†åˆä»¥éªŒè¯è¿æ¥å’Œé›†åˆå­˜åœ¨
        old_collection = client.get_collection(name=COLLECTION_NAME)
        count = old_collection.count()
        print(f"âœ… è¿æ¥æˆåŠŸ! å½“å‰é›†åˆ '{COLLECTION_NAME}' ä¸­å…±æœ‰ {count} æ¡æ•°æ®ã€‚")
    except Exception as e:
        print(f"âŒ è¿æ¥æˆ–è·å–é›†åˆå¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ PERSIST_DIRECTORY å’Œ COLLECTION_NAME æ˜¯å¦é…ç½®æ­£ç¡®ã€‚")
        return

    if count == 0:
        print("âš ï¸ é›†åˆä¸ºç©ºï¼Œæ— éœ€æ‰§è¡Œä¿®å¤æ“ä½œã€‚")
        return

    print("\nğŸ“¦ æ­¥éª¤ 1: å°†æ‰€æœ‰æ•°æ®åˆ†æ‰¹è¯»å–åˆ°å†…å­˜ä¸­...")

    all_ids = []
    all_embeddings = []
    all_metadatas = []
    all_documents = []

    batch_size = 1000  # è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥é€‚åº”æ‚¨çš„å†…å­˜æƒ…å†µ
    offset = 0

    start_time = time.monotonic()

    while offset < count:
        try:
            results = old_collection.get(
                limit=batch_size,
                offset=offset,
                include=["metadatas", "documents", "embeddings"],
            )

            if not results.get("ids"):
                break  # æ²¡æœ‰æ›´å¤šæ•°æ®äº†

            all_ids.extend(results["ids"])
            all_embeddings.extend(results["embeddings"])
            all_metadatas.extend(results["metadatas"])
            all_documents.extend(results["documents"])

            # ä½¿ç”¨ \r å®ç°åŸåœ°æ›´æ–°ï¼Œé¿å…åˆ·å±
            print(f"   å·²è¯»å– {len(all_ids)} / {count} æ¡...", end="\r")
            offset += batch_size

        except Exception as e:
            print(f"\nâŒ åœ¨åç§»é‡ {offset} å¤„è¯»å–æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            print("   è¿™å¯èƒ½è¡¨æ˜ SQLite æ•°æ®æ–‡ä»¶æœ¬èº«ä¹Ÿå·²æŸåã€‚æ“ä½œæ— æ³•ç»§ç»­ã€‚")
            return

    end_time = time.monotonic()
    print(f"\nâœ… æ•°æ®å…¨éƒ¨è¯»å–å®Œæ¯•ï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’ã€‚")

    print("\nğŸš¨ è­¦å‘Š: ä¸‹ä¸€æ­¥å°†æ°¸ä¹…åˆ é™¤å¹¶é‡å»ºé›†åˆã€‚è¯·åŠ¡å¿…ç¡®è®¤æ‚¨å·²å¤‡ä»½äº† 'data' ç›®å½•ï¼")
    confirm = input("ğŸ‘‰ è¯·è¾“å…¥ 'yes' ä»¥ç»§ç»­æ‰§è¡Œ: ")
    if confirm.lower() != "yes":
        print("æ“ä½œå·²å–æ¶ˆã€‚")
        return

    # 2. åˆ é™¤æ—§é›†åˆ (è¿™å°†åˆ é™¤æŸåçš„ç´¢å¼•æ–‡ä»¶å’Œç›¸å…³æ•°æ®)
    print("\nğŸ—‘ï¸ æ­¥éª¤ 2: æ­£åœ¨åˆ é™¤æ—§é›†åˆï¼Œä»¥æ¸…é™¤æŸåçš„ç´¢å¼•...")
    try:
        client.delete_collection(name=COLLECTION_NAME)
        print(f"   é›†åˆ '{COLLECTION_NAME}' å·²æˆåŠŸåˆ é™¤ã€‚")
    except Exception as e:
        print(f"\nâŒ åˆ é™¤é›†åˆæ—¶å‡ºé”™: {e}")
        return

    # 3. é‡å»ºé›†åˆ
    print("\nğŸ†• æ­¥éª¤ 3: æ­£åœ¨åˆ›å»ºåŒåæ–°é›†åˆ...")
    try:
        new_collection = client.create_collection(name=COLLECTION_NAME)
        print(f"   æ–°é›†åˆ '{COLLECTION_NAME}' åˆ›å»ºæˆåŠŸã€‚")
    except Exception as e:
        print(f"\nâŒ åˆ›å»ºæ–°é›†åˆæ—¶å‡ºé”™: {e}")
        return

    # 4. é‡æ–°å†™å…¥æ•°æ® (è¿™å°†è§¦å‘å…¨æ–°çš„ã€å¥åº·çš„ç´¢å¼•æ„å»º)
    print("\nğŸ’¾ æ­¥éª¤ 4: æ­£åœ¨å°†æ•°æ®åˆ†æ‰¹å†™å›æ–°é›†åˆï¼Œå¹¶è‡ªåŠ¨æ„å»ºæ–°ç´¢å¼•...")

    total_batches = (len(all_ids) + batch_size - 1) // batch_size
    start_time = time.monotonic()

    for i in range(total_batches):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, len(all_ids))

        print(
            f"   æ­£åœ¨å†™å…¥æ‰¹æ¬¡ {i + 1}/{total_batches} (æ¡ç›® {start_idx} - {end_idx})...",
            end="\r",
        )

        new_collection.add(
            ids=all_ids[start_idx:end_idx],
            embeddings=all_embeddings[start_idx:end_idx],
            metadatas=all_metadatas[start_idx:end_idx],
            documents=all_documents[start_idx:end_idx],
        )

    end_time = time.monotonic()
    print(f"\nâœ… æ•°æ®å…¨éƒ¨å†™å…¥å®Œæ¯•ï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’ã€‚")

    final_count = new_collection.count()
    print("\nğŸ‰ ä¿®å¤å®Œæˆï¼ç´¢å¼•å·²æˆåŠŸé‡å»ºã€‚")
    print(f"   - åŸå§‹æ•°æ®é‡: {count}")
    print(f"   - ä¿®å¤åæ•°æ®é‡: {final_count}")

    if count != final_count:
        print(
            f"   âš ï¸ è­¦å‘Š: æ•°æ®é‡ä¸åŒ¹é…ï¼å¯èƒ½åœ¨è¿‡ç¨‹ä¸­ä¸¢å¤±äº† {count - final_count} æ¡æ•°æ®ã€‚"
        )
    else:
        print("   âœ… æ•°æ®é‡ä¸€è‡´ï¼Œä¿®å¤æˆåŠŸï¼")


if __name__ == "__main__":
    fix_index()
